{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a808ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "    \n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, NNConv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import train_test_split_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba15ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADED\n",
      "Data(x=[26, 1], edge_index=[2, 26], edge_attr=[26, 1], y=[26, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%run dataset_ep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdad8a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs total: 111\n",
      "Number of training graphs: 111\n",
      "Number of test graphs: 73\n",
      "Data(x=[59, 1], edge_index=[2, 64], edge_attr=[64, 1], y=[64, 19])\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "dataset = dataset_ep.shuffle()\n",
    "\n",
    "# train_dataset = dataset[:int(len(dataset) * 0.65)]\n",
    "train_dataset = dataset[:int(len(dataset) * 1)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.35):]\n",
    "\n",
    "print(f'Number of graphs total: {len(dataset)}')\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "print(dataset[0])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f956016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, Data\n",
    "\n",
    "NUM_GRAPHS_PER_BATCH = len(dataset)\n",
    "NUM_HIDDEN_CHANNELS = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "727eb579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3026, 1], edge_index=[2, 3220], edge_attr=[3220, 1], y=[3220, 19])\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "edge_index = []\n",
    "edge_attr = []\n",
    "y = []\n",
    "for batch in train_loader:\n",
    "    x = batch.x\n",
    "    edge_index = batch.edge_index\n",
    "    edge_attr = batch.edge_attr\n",
    "    y = batch.y\n",
    "\n",
    "data = Data(x=x, \n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=y,\n",
    "            ) \n",
    "\n",
    "num_nodes = data.x.shape[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64fe244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1006, 1], y=[1053, 16], val_pos_edge_index=[2, 29], val_pos_edge_attr=[29, 1], test_pos_edge_index=[2, 58], test_pos_edge_attr=[58, 1], train_pos_edge_index=[2, 1000], train_pos_edge_attr=[1000, 1], train_neg_adj_mask=[1006, 1006], val_neg_edge_index=[2, 29], test_neg_edge_index=[2, 58])\n"
     ]
    }
   ],
   "source": [
    "split_data = train_test_split_edges(data)\n",
    "print(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ddf355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081c3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c6bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        conv_model = torch_geometric.nn.SAGEConv\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.emb = emb\n",
    "\n",
    "        assert (self.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(self.num_layers - 1):\n",
    "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(self.dropout),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        # Return node embeddings after post-message passing if specified\n",
    "        if self.emb:\n",
    "            return x\n",
    "\n",
    "        # Else return class probabilities for each node\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d07286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.lins.append(nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98bf8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, link_predictor, emb, edge_index, pos_train_edge, batch_size, optimizer):\n",
    "    \"\"\"\n",
    "    Runs offline training for model, link_predictor and node embeddings given the message\n",
    "    edges and supervision edges.\n",
    "    1. Updates node embeddings given the edge index (i.e. the message passing edges)\n",
    "    2. Computes predictions on the positive supervision edges\n",
    "    3. Computes predictions on the negative supervision edges (which are sampled)\n",
    "    4. Computes the loss on the positive and negative edges and updates parameters\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    link_predictor.train()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for edge_id in DataLoader(range(pos_train_edge.shape[0]), batch_size, shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        node_emb = model(emb, edge_index)  # (N, d)\n",
    "\n",
    "        pos_edge = pos_train_edge[edge_id].T  # (2, B)\n",
    "        pos_pred = link_predictor(node_emb[pos_edge[0]], node_emb[pos_edge[1]])  # (B, )\n",
    "\n",
    "        neg_edge = negative_sampling(edge_index, num_nodes=emb.shape[0],\n",
    "                                     num_neg_samples=edge_id.shape[0], method='dense')  # (Ne,2)\n",
    "        neg_pred = link_predictor(node_emb[neg_edge[0]], node_emb[neg_edge[1]])  # (Ne,)\n",
    "\n",
    "        loss = -torch.log(pos_pred + 1e-15).mean() - torch.log(1 - neg_pred + 1e-15).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    return sum(train_losses) / len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5547aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, predictor, emb, edge_index, split_edge, batch_size, evaluator):\n",
    "    \"\"\"\n",
    "    Evaluates model on positive and negative test edges\n",
    "    1. Computes the updated node embeddings given the edge index (i.e. the message passing edges)\n",
    "    2. Computes predictions on the positive and negative edges\n",
    "    3. Calculates hits @ k given predictions using the ogb evaluator\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    node_emb = model(emb, edge_index)\n",
    "\n",
    "    pos_test_edge = split_edge['test']['edge'].to(emb.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(emb.device)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(node_emb[edge[0]], node_emb[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(node_emb[edge[0]], node_emb[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [20, 50, 100]:\n",
    "        evaluator.K = K #using the Evaluator function in the ogb.linkproppred package\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = test_hits\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "from torch.optim import optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "optim_wd = 0\n",
    "epochs = 300\n",
    "hidden_dim = 256\n",
    "dropout = 0.2\n",
    "num_layers = 2\n",
    "lr = 3e-3\n",
    "node_emb_dim = 256\n",
    "batch_size = 64 * 1024\n",
    "\n",
    "edge_index = data.edge_index.to(device)\n",
    "\n",
    "evaluator = Evaluator(name='ogbl-ddi')\n",
    "\n",
    "# Create embedding, model, and optimizer\n",
    "emb = torch.nn.Embedding(num_nodes, node_emb_dim).to(device)\n",
    "model = GNNStack(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout, emb=True).to(device)\n",
    "link_predictor = LinkPredictor(hidden_dim, hidden_dim, 1, num_layers + 1, dropout).to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(model.parameters()) + list(link_predictor.parameters()) + list(emb.parameters()),\n",
    "    lr=lr, weight_decay=optim_wd\n",
    ")\n",
    "\n",
    "for e in range(epochs):\n",
    "    loss = train(model, link_predictor, emb.weight, edge_index, pos_train_edge, batch_size, optimizer)\n",
    "    print(f\"Epoch {e + 1}: loss: {round(loss, 5)}\")\n",
    "\n",
    "    if (e + 1) % 10 == 0:\n",
    "        result = test(model, link_predictor, emb.weight, edge_index, split_edge, batch_size, evaluator)\n",
    "        print(f\"{result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbaee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c24b3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "\n",
    "# Download and process data at './dataset/ogbl-ddi/'\n",
    "dataset = PygLinkPropPredDataset(name=\"ogbl-ddi\", root='./examples/')\n",
    "split_edge = dataset.get_edge_split()\n",
    "pos_train_edge = split_edge['train']['edge']\n",
    "\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a18d2a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[48, 1], edge_index=[2, 51], edge_attr=[51, 1], y=[51, 16])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47c0f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1067911, 2])\n",
      "torch.Size([1067911, 2])\n"
     ]
    }
   ],
   "source": [
    "print(pos_train_edge.shape)\n",
    "print(pos_train_edge.t().contiguous().t().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd53e3",
   "metadata": {},
   "source": [
    "- Unternehmensmodelle Beschreibung, Nutzung, Erstellung (4EM) etc.\n",
    "- Einführung neurale Netze\n",
    "- Einführung graph neural networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyg_env]",
   "language": "python",
   "name": "conda-env-pyg_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
