{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3496cd35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np \n",
    "import os\n",
    "        \n",
    "#print(f\"Torch version: {torch.__version__}\")\n",
    "#print(f\"Numpy version: {np.__version__}\")\n",
    "#print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79fa2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "tree = ET.parse('./data/raw/all2.xml')\n",
    "root = tree.getroot()\n",
    "#print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316206e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_models = root[0]\n",
    "model_classes = []\n",
    "\n",
    "for m in xml_models:\n",
    "    model_classes.append(m.attrib[\"modeltype\"])\n",
    "    \n",
    "model_classes = list(set(model_classes))\n",
    "\n",
    "num_model_classes = len(model_classes)\n",
    "\n",
    "def get_model_class(model):\n",
    "    return model_classes.index(model.attrib[\"modeltype\"])\n",
    "\n",
    "\n",
    "#pp.pprint(model_classes)\n",
    "#print(len(model_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeffe4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_models = root[0]\n",
    "model_data = []\n",
    "node_classes = []\n",
    "edge_classes = []\n",
    "\n",
    "for m in xml_models:\n",
    "    instances = [el for el in m if el.tag == \"INSTANCE\"]\n",
    "    connectors = [el for el in m if el.tag == \"CONNECTOR\"]\n",
    "    \n",
    "    for instance in instances:\n",
    "        node_class = instance.attrib[\"class\"]\n",
    "        node_classes.append(node_class)\n",
    "    \n",
    "    for connector in connectors:\n",
    "        edge_type = next(filter(lambda attr: attr.get(\"name\") == \"Type\", connector.findall(\"ATTRIBUTE\"))).text\n",
    "        if(edge_type is None):\n",
    "            edge_type = \"none\"\n",
    "        edge_classes.append(edge_type.lower())\n",
    "        \n",
    "    \n",
    "node_classes = list(set(node_classes))\n",
    "edge_classes = list(set(edge_classes))\n",
    "\n",
    "num_node_classes = len(node_classes)\n",
    "num_edge_classes = len(edge_classes)\n",
    "\n",
    "#pp.pprint(node_classes)\n",
    "#print(len(node_classes))\n",
    "#pp.pprint(edge_classes)\n",
    "#print(len(edge_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9064a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnterpriseModelDatasetGC(Dataset):\n",
    "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        self.num_classes = len(model_classes)\n",
    "        super(EnterpriseModelDatasetGC, self).__init__(root, transform, pre_transform)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filename\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return \"unimplemented.pt\"\n",
    "        if self.test:\n",
    "            return [f'data_test_{i}.pt' for i in range(len(xml_models))]\n",
    "        else:\n",
    "            return [f'data_{i}.pt' for i in range(len(xml_models))]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        xml_models = root[0]\n",
    "        index = 0\n",
    "        \n",
    "        for m in xml_models:\n",
    "            model = {}\n",
    "            nodes = []\n",
    "            edges = []\n",
    "            adjacency_list = []\n",
    "\n",
    "            nodes_data = []\n",
    "            edges_data = []\n",
    "\n",
    "            model[\"class\"] = get_model_class(m)\n",
    "\n",
    "            instances = [el for el in m if el.tag == \"INSTANCE\"]\n",
    "            connectors = [el for el in m if el.tag == \"CONNECTOR\"]\n",
    "\n",
    "        \n",
    "            for instance in instances:\n",
    "                node = {}\n",
    "                node_class = instance.attrib[\"class\"]\n",
    "                node_name = instance.attrib[\"name\"]\n",
    "                node[\"class\"] = node_class\n",
    "                node[\"name\"] = node_name\n",
    "                nodes_data.append(node)\n",
    "\n",
    "                # Dataset relevant\n",
    "               # node_features = [node_class, 0]\n",
    "                nodes.append([node_classes.index(node_class)])\n",
    "        \n",
    "            for connector in connectors:\n",
    "                edge = {}\n",
    "                edge_type = next(filter(lambda attr: attr.get(\"name\") == \"Type\", connector.findall(\"ATTRIBUTE\"))).text\n",
    "                if(edge_type is None):\n",
    "                    edge_type = \"none\"\n",
    "                else:\n",
    "                    edge_type = edge_type.lower()\n",
    "                edge[\"type\"] = edge_type\n",
    "\n",
    "                connector_from = connector.find(\"FROM\").get(\"instance\")\n",
    "                connector_to = connector.find(\"TO\").get(\"instance\")\n",
    "                edge[\"from\"] = connector_from\n",
    "                edge[\"to\"] = connector_to\n",
    "                edges_data.append(edge)\n",
    "\n",
    "                from_index = [node_data[\"name\"] for node_data in nodes_data].index(connector_from)\n",
    "                to_index = [node_data[\"name\"] for node_data in nodes_data].index(connector_to)\n",
    "                \n",
    "                adjacency_list.append([from_index, to_index])\n",
    "                edges.append([edge_classes.index(edge_type)])\n",
    "        \n",
    "            model[\"nodes\"] = torch.tensor(nodes, dtype=torch.float)\n",
    "            model[\"edges\"] = torch.tensor(edges, dtype=torch.float)\n",
    "            model[\"adjacency\"] = torch.tensor(adjacency_list, dtype=torch.int64)\n",
    "\n",
    "            model[\"nodes_data\"] = nodes_data\n",
    "            model[\"edges_data\"] = edges_data\n",
    "            \n",
    "            \n",
    "         # Create data object\n",
    "            data = Data(x=model[\"nodes\"], \n",
    "                        edge_index= model[\"adjacency\"].t().contiguous(),\n",
    "                        edge_attr=model[\"edges\"],\n",
    "                        y=model[\"class\"],\n",
    "                        ) \n",
    "            if self.test:\n",
    "                torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_test_{index}.pt'))\n",
    "            else:\n",
    "                torch.save(data, \n",
    "                    os.path.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "            \n",
    "            index += 1\n",
    "\n",
    "        \n",
    "    def len(self):\n",
    "        return len(xml_models)\n",
    "\n",
    "    def get(self, idx):\n",
    "        if self.test:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_test_{idx}.pt'))\n",
    "        else:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_{idx}.pt'))   \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab2a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_gc = EnterpriseModelDatasetGC(root=\"./data/gc_data\", filename=\"./raw/all2.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ecdb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LOADED\n",
      "EnterpriseModelDatasetGC(110)\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET LOADED\")\n",
    "print(dataset_gc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyg_env]",
   "language": "python",
   "name": "conda-env-pyg_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
