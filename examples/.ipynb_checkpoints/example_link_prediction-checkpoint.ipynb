{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5032c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        conv_model = torch_geometric.nn.SAGEConv\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.emb = emb\n",
    "\n",
    "        assert (self.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(self.num_layers - 1):\n",
    "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(self.dropout),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        # Return node embeddings after post-message passing if specified\n",
    "        if self.emb:\n",
    "            return x\n",
    "\n",
    "        # Else return class probabilities for each node\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b40f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.lins.append(nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, link_predictor, emb, edge_index, pos_train_edge, batch_size, optimizer):\n",
    "    \"\"\"\n",
    "    Runs offline training for model, link_predictor and node embeddings given the message\n",
    "    edges and supervision edges.\n",
    "    1. Updates node embeddings given the edge index (i.e. the message passing edges)\n",
    "    2. Computes predictions on the positive supervision edges\n",
    "    3. Computes predictions on the negative supervision edges (which are sampled)\n",
    "    4. Computes the loss on the positive and negative edges and updates parameters\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    link_predictor.train()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for edge_id in DataLoader(range(pos_train_edge.shape[0]), batch_size, shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        node_emb = model(emb, edge_index)  # (N, d)\n",
    "\n",
    "        pos_edge = pos_train_edge[edge_id].T  # (2, B)\n",
    "        pos_pred = link_predictor(node_emb[pos_edge[0]], node_emb[pos_edge[1]])  # (B, )\n",
    "\n",
    "        neg_edge = negative_sampling(edge_index, num_nodes=emb.shape[0],\n",
    "                                     num_neg_samples=edge_id.shape[0], method='dense')  # (Ne,2)\n",
    "        neg_pred = link_predictor(node_emb[neg_edge[0]], node_emb[neg_edge[1]])  # (Ne,)\n",
    "\n",
    "        loss = -torch.log(pos_pred + 1e-15).mean() - torch.log(1 - neg_pred + 1e-15).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    return sum(train_losses) / len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc03e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, predictor, emb, edge_index, split_edge, batch_size, evaluator):\n",
    "    \"\"\"\n",
    "    Evaluates model on positive and negative test edges\n",
    "    1. Computes the updated node embeddings given the edge index (i.e. the message passing edges)\n",
    "    2. Computes predictions on the positive and negative edges\n",
    "    3. Calculates hits @ k given predictions using the ogb evaluator\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    node_emb = model(emb, edge_index)\n",
    "\n",
    "    pos_test_edge = split_edge['test']['edge'].to(emb.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(emb.device)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(node_emb[edge[0]], node_emb[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(node_emb[edge[0]], node_emb[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [20, 50, 100]:\n",
    "        evaluator.K = K #using the Evaluator function in the ogb.linkproppred package\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = test_hits\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafcf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "from torch.optim import optimizer\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from gnn_stack import GNNStack\n",
    "from train import train\n",
    "from link_predictor import LinkPredictor\n",
    "from evaluate import test\n",
    "from utils import print_and_log\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Script to train link prediction in offline graph setting\")\n",
    "parser.add_argument('--epochs', type=int, default=300,\n",
    "                    help=\"Number of epochs for training\")\n",
    "parser.add_argument('--lr', type=float, default=3e-3,\n",
    "                    help=\"Learning rate training\")\n",
    "parser.add_argument('--node_dim', type=int, default=256,\n",
    "                    help='Embedding dimension for nodes')\n",
    "parser.add_argument('--dropout', type=float, default=0.3)\n",
    "parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
    "parser.add_argument('--num_layers', type=int, default=2)\n",
    "parser.add_argument('--hidden_channels', type=int, default=256)\n",
    "parser.add_argument('--exp_dir', type=str, default=None,\n",
    "                    help=\"Path to exp dir for model checkpoints and experiment logs\")\n",
    "args = parser.parse_args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "optim_wd = 0\n",
    "epochs = 300\n",
    "hidden_dim = 256\n",
    "dropout = 0.2\n",
    "num_layers = 2\n",
    "lr = 3e-3\n",
    "node_emb_dim = 256\n",
    "batch_size = 64 * 1024\n",
    "if exp_dir is None:\n",
    "    exp_dir = \"./experiments\"\n",
    "    dir = f\"offline.epochs:{epochs}.lr{lr}.layers:{num_layers}\" \\\n",
    "          f\".hidden_dim:{hidden_dim}.node_dim:{node_emb_dim}.init_batch_size:{batch_size}\"\n",
    "    exp_dir = os.path.join(exp_dir, dir)\n",
    "\n",
    "model_dir = os.path.join(exp_dir, 'checkpoints')\n",
    "logs_dir = os.path.join(exp_dir, 'logs')\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "logfile_path = os.path.join(logs_dir, 'log.txt')\n",
    "logfile = open(logfile_path, \"a\" if os.path.isfile(logfile_path) else \"w\", buffering=1)\n",
    "\n",
    "# Download and process data at './dataset/ogbl-ddi/'\n",
    "dataset = PygLinkPropPredDataset(name=\"ogbl-ddi\", root='./dataset/')\n",
    "split_edge = dataset.get_edge_split()\n",
    "pos_train_edge = split_edge['train']['edge'].to(device)\n",
    "\n",
    "graph = dataset[0]\n",
    "edge_index = graph.edge_index.to(device)\n",
    "\n",
    "evaluator = Evaluator(name='ogbl-ddi')\n",
    "\n",
    "# Create embedding, model, and optimizer\n",
    "emb = torch.nn.Embedding(graph.num_nodes, node_emb_dim).to(device)\n",
    "model = GNNStack(node_emb_dim, hidden_dim, hidden_dim, num_layers, dropout, emb=True).to(device)\n",
    "link_predictor = LinkPredictor(hidden_dim, hidden_dim, 1, num_layers + 1, dropout).to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(model.parameters()) + list(link_predictor.parameters()) + list(emb.parameters()),\n",
    "    lr=lr, weight_decay=optim_wd\n",
    ")\n",
    "\n",
    "for e in range(epochs):\n",
    "    loss = train(model, link_predictor, emb.weight, edge_index, pos_train_edge, batch_size, optimizer)\n",
    "    print_and_log(logfile, f\"Epoch {e + 1}: loss: {round(loss, 5)}\")\n",
    "\n",
    "    if (e + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, f\"model_{e + 1}.pt\"))\n",
    "        torch.save(emb.state_dict(), os.path.join(model_dir, f\"emb_{e + 1}.pt\"))\n",
    "        torch.save(link_predictor.state_dict(), os.path.join(model_dir, f\"link_pred_{e + 1}.pt\"))\n",
    "        result = test(model, link_predictor, emb.weight, edge_index, split_edge, batch_size, evaluator)\n",
    "        print_and_log(logfile, f\"{result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4cda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b8de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e3418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320aeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyg_env]",
   "language": "python",
   "name": "conda-env-pyg_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
